{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/tucker/sabbatical/predict_bert_embeddings/char_lm/token_start_pred\r\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'results/561fdb2f9'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-298a945c8c33>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mexp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'results/%s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mexphash\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m   \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msafe_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'exp_info'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'results/561fdb2f9'"
     ]
    }
   ],
   "source": [
    "import plotly\n",
    "import plotly.graph_objs as go\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from experiment import Net, InitDataset, CreateModel, LoadCheckpoint\n",
    "from yaml import safe_load\n",
    "import torch.nn as nn\n",
    "exphash = '561fdb2f9'\n",
    "\n",
    "exp = 'results/%s' % exphash\n",
    "with open(exp) as f:\n",
    "  h = safe_load(f.read())\n",
    "h = h['exp_info']  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'h' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mNameError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-33cf25fe7592>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mh\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'dataset_split'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m.1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mInitDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'cuda'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'h' is not defined"
     ]
    }
   ],
   "source": [
    "h['dataset_split'][0] = .1\n",
    "ds = InitDataset(h, 'cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[12:10:21] Loaded model: <All keys matched successfully>\n"
     ]
    }
   ],
   "source": [
    "model = CreateModel(h['hyperparameters'])\n",
    "LoadCheckpoint(model, 'models/%s'%exphash)\n",
    "\n",
    "model = model.cuda()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([200091, 96])\n",
      "torch.Size([200091, 96, 2])\n",
      "torch.Size([200091, 384])\n"
     ]
    }
   ],
   "source": [
    "a = torch.load('imdb_tok96_char_encoded384charidx2.pt')\n",
    "for k in a.keys():\n",
    "  print(a[k].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'b' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mNameError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-c9d909bf34b5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0ma\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'token_start_offsets'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'token_start_offsets'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'b' is not defined"
     ]
    }
   ],
   "source": [
    "a['token_start_offsets'].shape, b['token_start_offsets'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['token_start_offsets', 'chars_encoded'])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = torch.load('news2007_tok96_char384_enc_no_tok.pt')\n",
    "b.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([200091, 384])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a['chars_encoded'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.19511365076888573"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a['chars_encoded'].shape[0]/b['chars_encoded'].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "val_loader = DataLoader(ds[1], batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "idx_to_char_map = {v:k for k,v in torch.load('../data/char_to_idx_map2.pt').items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "idx_to_char_map[0] = '_'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Torch2Py = lambda x: x.cpu().numpy().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def bin_acc_fn(outputs, labels):\n",
    "  binary = outputs>.5\n",
    "  right = binary==labels\n",
    "  return right.float()\n",
    "\n",
    "BCE_loss = nn.BCELoss(reduction='none')\n",
    "def bce_loss_fn(outputs, labels):\n",
    "  return BCE_loss(outputs, labels)\n",
    "\n",
    "def Validate(val_loader, model):\n",
    "  device = next(model.parameters()).device\n",
    "  cum_acc = 0\n",
    "  cum_bce_loss = 0\n",
    "\n",
    "  inputs_ = []\n",
    "  losses_ = []\n",
    "  guesses_ = []\n",
    "  rights_ = []\n",
    "  labels_ = []\n",
    "  for i, data in enumerate(val_loader):\n",
    "    data = {k: d.to(device) for k,d in data.items()}\n",
    "    inputs = data['char_encoded_seqs']\n",
    "    inputs_ += Torch2Py(inputs)\n",
    "    labels = data['token_start_positions']\n",
    "    labels_ += Torch2Py(labels)\n",
    "\n",
    "    with torch.no_grad():\n",
    "      outputs = model(inputs)\n",
    "      guesses_ += Torch2Py(outputs)\n",
    "      bce_loss = bce_loss_fn(outputs, labels)\n",
    "      losses_ += Torch2Py(bce_loss)\n",
    "      cum_bce_loss += bce_loss.mean()\n",
    "\n",
    "      acc = bin_acc_fn(outputs, labels)\n",
    "      rights_ += Torch2Py(acc)\n",
    "      cum_acc += acc.mean()\n",
    "\n",
    "  print(cum_acc/(i+1), cum_bce_loss/(i+1))\n",
    "  return inputs_, losses_, rights_, labels_, guesses_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.9887, device='cuda:0') tensor(0.0449, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "inputs, losses, rights, labels, guesses = Validate(val_loader, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def GetChars(encoded):\n",
    "  s = \"\"\n",
    "  for c in encoded:\n",
    "    s+= idx_to_char_map[c]\n",
    "  return s.replace('\\x00','_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "c = GetChars(inputs[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"[cls] you're anyone else, i say just skip it. i can see that this films is mostly rated and commented by girls under 15. no one else could say one phrase to this rubbish. the movie was (as usual) higly boring, stiffly acted, predictable, like a big musicvideo. i simply can_t believe how anyone can write this unpleasant film___________________________________________________________\""
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [ y ' r a e , i s j s i . i c s t t f i m r a c b g u 1 . n o e c s o p t t r . t m w ( a u ) h g b , s a , p , l a b m v e . i s c _ t b h a c w t u f\n"
     ]
    }
   ],
   "source": [
    "s = \"\"\n",
    "for i, l in enumerate(labels[1]):\n",
    "  if l:\n",
    "    s+= \" \" + c[i]\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                                    \n",
      "                                                                                                    \n",
      "[cls] called tam lin (one of my favorites), long story short, a woman falls in love with a faerie, a\n",
      "                                                                                                    \n",
      "\n",
      "                                                                                                    \n",
      "                                                                                                    \n",
      "[cls] person of the same name. his sword can cut anything (except devil's tongue jelly, as i've hear\n",
      "                                                                                                    \n",
      "\n"
     ]
    }
   ],
   "source": [
    "length = 100\n",
    "for i, r in enumerate(rights[:30]):\n",
    "  if sum(r)<len(r) and i%10==0:\n",
    "    # underscore above the letter if a tok start was missed\n",
    "    print(\"\".join('_' if labels[i][j]==1 and x!=1 else ' ' for j, x in enumerate(rights[i][:length])))\n",
    "    print(\"\".join(str(int(guesses[i][j]*10)) if x!=1 else ' ' for j, x in enumerate(rights[i][:length])))    \n",
    "    print(GetChars(inputs[i])[:length])\n",
    "    print(\"\".join(' ' if x==1 else 'X' for x in rights[i][:length]))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "inps = torch.tensor([[32, 46, 55, 62, 33,  1,  3, 46, 15,  1, 63, 51, 58, 56, 44, 62,  3,  1,\n",
    "         56, 58, 65, 52, 48, 62,  1, 46, 58, 56, 48,  1, 58, 64, 63,  1, 44, 57,\n",
    "         47,  1, 63, 51, 48, 68,  1, 54, 48, 48, 59,  1, 36, 34,  1, 58, 49,  1,\n",
    "         63, 51, 48, 56,  1, 52, 57,  1, 32, 56, 33, 15,  1, 62, 58,  1, 47, 58,\n",
    "         57,  8, 63,  1, 45, 48,  1, 49, 58, 58, 55, 48, 47,  1, 45, 68,  1, 63,\n",
    "         51, 48,  1,  3, 66, 44, 61,  1, 58, 49,  1, 63, 51, 48,  1, 32, 56, 33,\n",
    "          3,  1, 52, 57,  1, 68, 58, 64, 61,  1, 56, 58, 65, 52, 48,  1, 62, 63,\n",
    "         58, 61, 48,  1, 61, 52, 50, 51, 63,  1, 57, 58, 66, 13,  1, 52, 63,  8,\n",
    "         62,  1, 44,  1, 45,  1, 56, 58, 65, 52, 48, 13,  1, 57, 58, 63,  1, 63,\n",
    "         58, 56,  1, 46, 61, 64, 52, 62, 48, 15,  1, 66, 58, 66,  2,  1, 63, 51,\n",
    "         52, 62,  1, 49, 52, 55, 56,  1, 52, 62,  1, 63, 51, 48,  1, 54, 52, 57,\n",
    "         47,  1, 58, 49,  1, 56, 58, 65, 52, 48,  1, 63, 51, 44, 63,  1, 45, 61,\n",
    "         52, 57, 50, 62,  1, 63, 48, 44, 61, 62,  1, 63, 58,  1, 68, 58, 64, 61,\n",
    "          1, 48, 68, 48, 62,  1, 44, 57, 47,  1, 66, 44, 61, 56, 63, 51,  1, 63,\n",
    "         58,  1, 68, 58, 64, 61,  1, 51, 48, 44, 61, 63, 15,  1, 48, 65, 48, 61,\n",
    "         68, 58, 57, 48,  1, 46, 58, 57, 57, 48, 46, 63, 48, 47,  1, 63, 58,  0,\n",
    "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
    "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
    "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
    "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
    "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
    "          0,  0,  0,  0,  0,  0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  5.0432,  -9.6778,  -9.4772,  -8.0009,  -6.5148,  -6.6421,   5.0432,\n",
       "           5.0432,   5.0432,  -6.1596,   5.0432,  -8.1841,  -6.0874,  -3.6117,\n",
       "          -3.6587,  -3.1781,   5.0432,  -5.1844,   5.0432,  -8.3513,  -6.5491,\n",
       "          -7.0170,  -5.1324,  -4.3156,  -5.4401,   5.0432,  -8.8702,  -9.8983,\n",
       "          -5.9861,  -6.6557,   5.0432,  -8.0304,  -6.3259,  -6.1351,   5.0432,\n",
       "         -10.3148,  -7.6387,  -5.9214,   5.0432,  -7.8010,  -7.5255,  -4.4341,\n",
       "          -6.5001,   5.0432,  -8.8810,  -4.1256,  -3.8710,  -6.5042,   5.0432,\n",
       "          -5.9635,  -5.0427,   5.0432,  -8.2271,  -6.1824,   5.0432, -10.1565,\n",
       "          -7.1697,  -4.2351,  -6.5331,   5.0432,  -7.7881,  -6.6663,   5.0432,\n",
       "           5.0432,  -1.4903,   5.0432,  -6.1073,   5.0432,  -6.7565,  -5.9914,\n",
       "           5.0432,  -8.4409,  -6.7468,   5.0432,   5.0432,  -5.5495,   5.0432,\n",
       "          -6.9397,  -5.4059,   5.0432,  -6.4460,  -3.8810,  -3.7247,  -3.6886,\n",
       "          -3.8050,  -5.8272,   5.0432,  -6.6779,  -6.3090,   5.0432,  -9.4818,\n",
       "          -7.8624,  -7.5359,   5.0432,   5.0432,  -9.4451,  -6.3788,  -6.1966,\n",
       "           5.0432,  -6.6777,  -6.0441,   5.0432,  -9.8634,  -7.4912,  -6.9413,\n",
       "           5.0432,   5.0432,  -2.9897,   5.0432,  -5.8912,   5.0432,  -8.2986,\n",
       "          -6.7492,   5.0432,  -7.9059,  -6.2811,  -5.4334,  -5.6047,   5.0432,\n",
       "          -8.9955,  -7.8166,  -8.8530,  -6.9434,  -6.8630,   5.0432,  -8.0210,\n",
       "          -7.2181,  -6.9199,  -7.1211,  -7.1615,   5.0432,  -8.6359,  -7.0708,\n",
       "          -6.7732,  -6.1281,  -5.3324,   5.0432,  -7.7998,  -4.8959,   5.0432,\n",
       "          -6.4074,   5.0432,  -5.7839,   5.0432,   5.0432,  -4.8992,   5.0432,\n",
       "          -5.1815,   5.0432,  -6.3992,   5.0432,  -9.5593,  -7.3331,  -7.5307,\n",
       "          -5.9381,   5.0432,  -5.2607,   5.0432,  -7.6274,  -6.9570,  -5.0325,\n",
       "           5.0432,  -7.6271,  -4.9328,  -5.7479,   5.0432,  -7.4278,  -3.9390,\n",
       "          -6.9511,  -4.5758,  -4.0735,   5.0432,  -6.2578,   5.0432,  -7.4296,\n",
       "          -4.9174,   5.0432,  -6.6916,   5.0432,  -8.4321,  -9.0045,  -6.5103,\n",
       "          -6.0090,   5.0432,  -8.5682,  -6.8683,  -6.0812,  -6.1926,   5.0432,\n",
       "          -6.1262,  -6.1808,   5.0432,  -8.5602,  -7.2455,  -5.3505,   5.0432,\n",
       "          -7.1292,  -5.9910,  -4.8348,  -6.1295,   5.0432,  -7.5158,  -6.3032,\n",
       "           5.0432,  -9.7485,  -7.3170,  -7.3957,  -5.8880,  -6.0728,   5.0432,\n",
       "          -8.4552,  -7.0915,  -6.6673,  -6.0514,   5.0432,  -7.4823,  -5.2214,\n",
       "          -7.9374,  -7.1766,  -2.7922,  -6.3885,   5.0432, -12.7033,  -8.5246,\n",
       "          -8.6394,  -5.1025,  -5.5493,   5.0432,  -7.4564,  -6.8789,   5.0432,\n",
       "          -8.5711,  -5.8860,  -5.5621,  -5.4761,   5.0432,  -5.3068,  -3.8332,\n",
       "          -4.4754,  -5.9368,   5.0432, -10.4227,  -7.1291,  -6.6639,   5.0432,\n",
       "         -11.7870,  -8.1327,  -3.8444,  -3.4262,  -4.5686,  -5.3954,   5.0432,\n",
       "          -7.7252,  -6.8720,   5.0432,  -9.2793,  -6.3917,  -6.0853,  -5.8924,\n",
       "           5.0432, -10.1346,  -5.8048,  -5.3780,  -4.5248,   5.0432,  -4.9630,\n",
       "           5.0432,  -7.5243,  -7.0448,  -6.0660,  -5.3727,  -5.0029,  -5.1314,\n",
       "          -5.0773,  -5.0964,   5.0432,  -8.3846,  -8.1159,  -5.1227,  -6.6399,\n",
       "          -5.0741,  -6.0393,  -3.9338,  -5.2850,  -5.5492,   5.0432,  -9.1036,\n",
       "          -9.4452, -10.6242, -14.4198, -15.7115, -15.7115, -15.7115, -15.7115,\n",
       "         -15.7115, -15.7115, -15.7115, -15.7115, -15.7115, -15.7115, -15.7115,\n",
       "         -15.7115, -15.7115, -15.7115, -15.7115, -15.7115, -15.7115, -15.7115,\n",
       "         -15.7115, -15.7115, -15.7115, -15.7115, -15.7115, -15.7115, -15.7115,\n",
       "         -15.7115, -15.7115, -15.7115, -15.7115, -15.7115, -15.7115, -15.7115,\n",
       "         -15.7115, -15.7115, -15.7115, -15.7115, -15.7115, -15.7115, -15.7115,\n",
       "         -15.7115, -15.7115, -15.7115, -15.7115, -15.7115, -15.7115, -15.7115,\n",
       "         -15.7115, -15.7115, -15.7115, -15.7115, -15.7115, -15.7115, -15.7115,\n",
       "         -15.7115, -15.7115, -15.7115, -15.7115, -15.7115, -15.7115, -15.7115,\n",
       "         -15.7115, -15.7115, -15.7115, -15.7115, -15.7115, -15.7115, -15.7115,\n",
       "         -15.7115, -15.7115, -15.7115, -15.7115, -15.7115, -15.7115, -15.7115,\n",
       "         -15.7115, -15.7115, -15.7115, -15.7115, -15.7115, -15.7115, -15.7115,\n",
       "         -15.7115, -15.7115, -15.7115, -15.7115, -15.6949, -15.6237, -15.1956,\n",
       "         -14.8291, -15.0875, -15.4671, -15.0583, -20.7412, -18.7139]],\n",
       "       device='cuda:0', grad_fn=<SqueezeBackward1>)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.tokens_start_attn(inps.cuda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "chrs = []\n",
    "for i in inputs:\n",
    "  chrs.append(GetChars(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/tucker/Downloads/strategy_heatmap.html'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import plotly.figure_factory as ff\n",
    "hm = ff.create_annotated_heatmap(\n",
    "  z=guesses[:12], annotation_text=chrs[:12],\n",
    "  text=guesses[:12], hoverinfo='text')\n",
    "\n",
    "plotly.offline.plot(hm, filename='/home/tucker/Downloads/strategy_heatmap.html')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "argv": [
    "/usr/bin/python3",
    "-m",
    "ipykernel_launcher",
    "-f",
    "{connection_file}"
   ],
   "display_name": "Python 3",
   "env": null,
   "interrupt_mode": "signal",
   "language": "python",
   "metadata": null,
   "name": "python3"
  },
  "name": "ErrorAnalysis.ipynb"
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
