{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/tucker/sabbatical/predict_bert_embeddings/char_lm/char_seq_to_masked_emb\r\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import plotly\n",
    "import plotly.graph_objs as go\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from experiment import Net, InitDataset, CreateModel, LoadCheckpoint, RunOne\n",
    "from yaml import safe_load\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "exphash = 'd40e3553d'\n",
    "exp = 'results/%s' % exphash\n",
    "with open(exp) as f:\n",
    "  h = safe_load(f.read())\n",
    "h = h['exp_info']  \n",
    "\n",
    "ds = InitDataset(h)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[20:59:09] loading configuration file bert_distil_uncased/config.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[20:59:09] loading weights file bert_distil_uncased/pytorch_model.bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[20:59:11] Loaded model: <All keys matched successfully>\n"
     ]
    }
   ],
   "source": [
    "#h['hyperparameters']['manual_attention'] = True\n",
    "model = CreateModel(h['hyperparameters'])\n",
    "LoadCheckpoint(model, 'models/%s'%exphash)\n",
    "\n",
    "model = model.cuda()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "h['dataset_split'][1] = .01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "val_loader = DataLoader(ds[1], batch_size=64, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([96])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds[0][0]['label_ids'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([  101,  2682,  1012,  2129,  2434,   999,  1007,  1012,  1998, 14397,\n",
       "         5740,  2003,  5129,  2011,  2200,  3492,  1006,  1998,  2402,  1007,\n",
       "         3057,  2040,  2024,  1999,  2293,  2007,  2032,  1012,  2129, 17203,\n",
       "         1012,  2065,  2017,  2428,  2066,  1996,  1000,  2613,  1000,  2632,\n",
       "        14397,  5740,  1010,  2123,  1005,  1056,  2130,  2228,  2000,  3422,\n",
       "         2023,  2143,  1012,  2017,  2453,  2022,  3724,  2000,  2228,  2008,\n",
       "         4469,  3334, 28533, 14482,  2015,  2031,  2999,  2032,  2007,  1037,\n",
       "         2919,  6100,  1012,  2632, 14397,  5740,  2003,  2028,  1997,  2216,\n",
       "         2261,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds[0][0]['label_ids']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Torch2Py = lambda x: x.cpu().numpy().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "xent = nn.CrossEntropyLoss()\n",
    "def xentropy_loss_fn(output, labels):\n",
    "  output = output.contiguous()  \n",
    "  return xent(output.view(-1, output.size(-1)), labels.view(-1))\n",
    "\n",
    "def top1_acc_fn(output, labels):\n",
    "  top = output.argmax(-1)\n",
    "  right = top==labels\n",
    "  return right.float()\n",
    "\n",
    "def Validate(val_loader, model):\n",
    "  device = next(model.parameters()).device\n",
    "  cum_acc = 0\n",
    "  cum_xent_loss = 0\n",
    "\n",
    "  rights_ = []\n",
    "  inputs_ =[]\n",
    "  labels_ =[]\n",
    "  maxes_ =[]\n",
    "  for i, data in enumerate(val_loader):\n",
    "    data = {k: d.to(device) for k,d in data.items()}\n",
    "    inputs = data['input_ids']\n",
    "    labels = data['label_ids']\n",
    "    inputs_ += Torch2Py(inputs)\n",
    "    labels_ += Torch2Py(labels)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "      \n",
    "      model.eval()\n",
    "      outputs = model(inputs)\n",
    "      maxes_ += Torch2Py(outputs.argmax(-1))\n",
    "      xent_loss = xentropy_loss_fn(outputs, labels)\n",
    "      cum_xent_loss += xent_loss      \n",
    "\n",
    "      top1_acc = top1_acc_fn(outputs, labels)\n",
    "      rights_ += Torch2Py(top1_acc)\n",
    "      cum_acc += top1_acc.mean()\n",
    "    if len(inputs_)>100:\n",
    "      break\n",
    "\n",
    "  steps = i+1\n",
    "  print(cum_acc/steps, cum_xent_loss.detach()/steps)\n",
    "  return rights_, inputs_, labels_, maxes_,\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1104, device='cuda:0') tensor(11.1539, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "right, inputs, labels, maxes = Validate(val_loader, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(128, 128, 128, 128)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(right), len(inputs), len(labels), len(maxes),"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([96, 768])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.embedded_chars[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "char_to_idx_map = torch.load('../data/char_to_idx_map2.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "idx_to_char_map= {v:k for k,v in char_to_idx_map.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "idx_to_tok_map = {}\n",
    "with open('../data/bert-base-uncased-vocab.txt') as f:\n",
    "  for i, l in enumerate(f.readlines()):\n",
    "    idx_to_tok_map[i] = l.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def GetChars(encoded):\n",
    "  s = \"\"\n",
    "  for c in encoded:\n",
    "    s+= idx_to_char_map[c]\n",
    "  return s.replace('\\x00','_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def GetToks(encoded):\n",
    "  s = \"\"\n",
    "  for c in encoded:\n",
    "    s+= \" \" + idx_to_tok_map[c]\n",
    "  return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "inps = ds[0][0]['input_ids'].unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "  a = ((model.embedded_chars[-1, 0:8, :].unsqueeze(1)-model.bert.distilbert.embeddings.word_embeddings.weight.data)**2).mean(-1).argmin(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([20, 1, 768])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.embedded_chars[-1, 0:20, :].unsqueeze(1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "  a = (model.embedded_chars[-1, 0:20, :].squeeze(1)@model.bert.distilbert.embeddings.word_embeddings.weight.data.T).argmax(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[cls] rat-pelts, is [m]. he scarcely looks human, [m] shadow-image of the successful doctor, yukio. [m]tekichi represents the oppression of japan's violent, disordered-past from the eras of the shogun and the samurai[m] yukio represents the emergence of a modern japan, with his work as a doctor and his bourgeois life with his new-wife[m] rin. he to[m] helping cure the______________\n"
     ]
    }
   ],
   "source": [
    "print(GetChars(inputs[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[cls] above. how original!). and pacino is [m] by very pretty (and [m]) girls who are in love [m] him. how pathetic. if you really like the \"real[m] al pacino, don\\'t even think to watch this film. you might be pushed to think that extraterrestrials [m] replaced him with a bad copy. al pacino is one of [m] few__________________________________________________________________________'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GetChars(Torch2Py(ds[0][0]['input_ids']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ) \" 7 ) is unknown . he hardly looks human \" ) shadow 15 of the young doctor ) ##yuki ) he represents the oppression of japan . violent ) disorder 15 from the birth of the earth and the samurai ##yuki represents the emergence of a modern japan , with his work as a doctor and his bourgeois life with his friend / ##s . he is help cure the [ [ [ [ [ [ , , , ... ... ... ... ... ... ##oh ##oh ##oh ##oh ##oh ##oh ##oh ##oh ##o\n"
     ]
    }
   ],
   "source": [
    "print(GetToks(maxes[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('[cls] [m](it remin',\n",
       " [32, 46, 55, 62, 33, 1, 32, 56, 33, 9, 52, 63, 1, 61, 48, 56, 52, 57])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "j = 0\n",
    "inp = inputs[4][j:j+18]\n",
    "GetChars(inp), inp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "inp = torch.tensor([[50, 64, 52, 63, 44, 61,  1, 35, 41, 40, 35,  1, 58, 45, 62, 46, 48, 57]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "out = model.char_embedder.tokens_to_emb(inp.cuda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#next(model.char_embedder.tokens_to_emb.named_parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.0719, -0.1866,  0.1774,  0.5457], device='cuda:0',\n",
       "       grad_fn=<SliceBackward>)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out[0][:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "word = (out@model.bert.distilbert.embeddings.word_embeddings.weight.data.T).argmax(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.0209, -0.0467, -0.0392, -0.0345,  0.0150, -0.0398, -0.0696, -0.0479,\n",
       "        -0.0290, -0.0037], device='cuda:0')"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.bert.distilbert.embeddings.word_embeddings.weight.data[2858][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2858], device='cuda:0', grad_fn=<NotImplemented>)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "word = ((out-model.bert.distilbert.embeddings.word_embeddings.weight.data)**2).mean(-1).argmin(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29\n"
     ]
    }
   ],
   "source": [
    "w = '[cls] guitars [m] some ot [m]'\n",
    "thing = []\n",
    "for c in w :\n",
    "  thing.append(char_to_idx_map[c])\n",
    "print(len(thing))\n",
    "inp = torch.tensor(thing).unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[22:44:05] Loaded model: <All keys matched successfully>\n"
     ]
    }
   ],
   "source": [
    "LoadCheckpoint(model.char_embedder, '../single_emb_pred/models/c26917206')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "out = model(inp.cuda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "out = model.embedded_chars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "out = model.char_embedder(inp.cuda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 96, 768])"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.5e-05"
      ]
     },
     "execution_count": 295,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    ".005**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2.5000e-05, 0.0000e+00, 0.0000e+00]])"
      ]
     },
     "execution_count": 294,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.nn.MSELoss(reduction='none')(torch.tensor([[.005, 0.0, 0.0]]), torch.tensor([[0.0, 0.0, 0.0]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "word = ((out[0, :4].unsqueeze(1)-model.bert.distilbert.embeddings.word_embeddings.weight.data)**2).mean(-1).argmin(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "word = (out@model.bert.distilbert.embeddings.word_embeddings.weight.data.T).argmax(-1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' [CLS] guitars [MASK] some'"
      ]
     },
     "execution_count": 281,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GetToks(Torch2Py(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "' [CLS] made of stories a where every story is great ; that'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [CLS] retired / it doesn in matter if\n"
     ]
    }
   ],
   "source": [
    "print(GetToks(Torch2Py(a)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " comedy at at at at at now at at at at at at at now at at comedy at at\n"
     ]
    }
   ],
   "source": [
    "print(GetToks(Torch2Py(a)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'tuple' object has no attribute 'data'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-05c3b8230e7c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0membeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'embeddings'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'tuple' object has no attribute 'data'"
     ]
    }
   ],
   "source": [
    "embeddings = ds.data['embeddings']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'embeddings' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mNameError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-c28bfc7a5958>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0membeddings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'embeddings' is not defined"
     ]
    }
   ],
   "source": [
    "embeddings.norm(2,-1).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "embedding_noise = .25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "r = torch.normal(mean=embedding_noise, std=1, size=embeddings.size()).cuda()\n",
    "norm_factor = torch.norm(r, 2, -1).mean()/embedding_noise\n",
    "normalized_noise = r/norm_factor\n",
    "new = embeddings + normalized_noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(8.1433e-05, device='cuda:0')"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "((new-embeddings)**2).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0072, device='cuda:0')"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sqrt((new-embeddings)**2).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n = new.norm(2,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def MakeHist(h, name=None):\n",
    "  y = h[0]\n",
    "  x= h[1]\n",
    "  return {\n",
    "    'name': name,\n",
    "    'type': 'bar',                                                                                                                   'x': x,\n",
    "          'marker': dict(opacity=.7),\n",
    "   'y': y\n",
    "  }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'n' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mNameError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-dc966d68458f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mdat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMakeHist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistogram\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbins\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'toks'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdat\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'barmode'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m'overlay'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'n' is not defined"
     ]
    }
   ],
   "source": [
    "dat = MakeHist(np.histogram(n, bins=30), name='toks')\n",
    "\n",
    "fig = fig = go.Figure(data=[dat], layout={'barmode':'overlay'})\n",
    "plotly.offline.plot(fig, filename='/home/tucker/Downloads/imdb_size_distci.html')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "attn = torch.nn.Sigmoid()(model.char_embedder.char_block_attn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/tucker/Downloads/strategy_heatmap.html'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hm = go.Heatmap(z=attn.detach().cpu().numpy())\n",
    "fig = go.Figure(data=[hm])\n",
    "plotly.offline.plot(fig, filename='/home/tucker/Downloads/strategy_heatmap.html')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sb = model.char_embedder.switchboard[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/tucker/Downloads/strategy_heatmap.html'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hm = go.Heatmap(z=sb.detach().cpu().numpy())\n",
    "fig = go.Figure(data=[hm])\n",
    "plotly.offline.plot(fig, filename='/home/tucker/Downloads/strategy_heatmap.html')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ds = CharClozeToDenseTokEmbDataset('imdb_tok96_char_encoded384.pt', num_masks=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "char_to_idx_map = torch.load('../data/char_to_idx_map.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "idx_to_char_map= {v:k for k,v in char_to_idx_map.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "idx_to_tok_map = {}\n",
    "with open('../data/bert-base-uncased-vocab.txt') as f:\n",
    "  for i, l in enumerate(f.readlines()):\n",
    "    idx_to_tok_map[i] = l.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def GetChars(encoded):\n",
    "  s = \"\"\n",
    "  for c in encoded:\n",
    "    s+= idx_to_char_map[c]\n",
    "  return s.replace('\\x00','_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def GetToks(encoded):\n",
    "  s = \"\"\n",
    "  for i, c in enumerate(encoded):\n",
    "    s+= \" %d.\"%i + idx_to_tok_map[c]\n",
    "  return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "list indices must be integers or slices, not str",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-7f974ae4cd4c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mGetChars\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTorch2Py\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'input_ids'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mGetChars\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTorch2Py\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'original'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mGetToks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTorch2Py\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'tokens'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.8/site-packages/torch/utils/data/dataset.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    255\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 257\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: list indices must be integers or slices, not str"
     ]
    }
   ],
   "source": [
    "print(GetChars(Torch2Py(ds[0]['input_ids'])))\n",
    "print(GetChars(Torch2Py(ds[0]['original'])))\n",
    "print(GetToks(Torch2Py(ds[0]['tokens'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(76)\n",
      "tensor([[ 72,  76],\n",
      "        [ 92,  95],\n",
      "        [ 96, 101],\n",
      "        [114, 115],\n",
      "        [116, 122],\n",
      "        [122, 123],\n",
      "        [126, 130],\n",
      "        [137, 138],\n",
      "        [139, 142],\n",
      "        [145, 150],\n",
      "        [162, 163],\n",
      "        [168, 171],\n",
      "        [192, 196],\n",
      "        [209, 213],\n",
      "        [220, 221],\n",
      "        [227, 233],\n",
      "        [234, 241],\n",
      "        [252, 253],\n",
      "        [253, 254],\n",
      "        [269, 272]], dtype=torch.int16)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([34, 42, 51, 58, 36,  1, 48,  1, 40, 43, 52, 48, 59, 13,  1, 59, 47, 44,\n",
       "          1, 46, 57, 44, 40, 59,  1, 52, 40, 49, 54, 57, 48, 59, 64,  1, 54, 45,\n",
       "          1, 45, 48, 51, 52, 58,  1, 57, 44, 51, 44, 40, 58, 44, 43,  1, 41, 44,\n",
       "         45, 54, 57, 44,  1, 58, 40, 64,  1, 18, 26, 20, 20,  1, 40, 57, 44,  1,\n",
       "         34, 38, 36,  1, 53, 54, 59,  1, 45, 54, 57,  1, 52, 44, 15,  1, 54, 45,\n",
       "          1, 34, 38, 36,  1, 34, 38, 36,  1, 54, 57,  1, 58, 54,  1,  3, 52, 40,\n",
       "         49, 54, 57, 34, 38, 36,  1, 34, 38, 36, 34, 38, 36,  1, 48,  1, 34, 38,\n",
       "         36,  1, 61, 48, 44, 62, 44, 43, 34, 38, 36,  1, 34, 38, 36,  1, 48,  1,\n",
       "         34, 38, 36,  1,  9, 59, 47, 44,  1, 42, 57, 54, 62, 43, 10, 34, 38, 36,\n",
       "          1, 40, 53, 43,  1, 34, 38, 36,  1, 62, 44, 57, 44,  1, 61, 44, 57, 64,\n",
       "          1, 46, 54, 54, 43,  1,  9, 59, 47, 44,  1, 34, 38, 36,  1, 42, 54, 52,\n",
       "         52, 40, 53, 43,  1, 40, 53, 43,  1, 34, 38, 36,  1, 51, 48, 46, 47, 59,\n",
       "         58, 34, 38, 36,  1, 59, 47, 40, 59,  1, 34, 38, 36,  1, 34, 38, 36,  1,\n",
       "         42, 48, 57, 42, 40,  1, 18, 26, 20, 18, 34, 38, 36, 34, 38, 36,  1, 58,\n",
       "         54,  1, 48,  1, 62, 40, 58,  1, 40, 55, 55, 57, 44, 34, 38, 36, 58, 48,\n",
       "         61, 44,  1, 40, 41, 54, 60, 59,  1, 59, 47, 48, 58,  1, 54, 53, 44, 13,\n",
       "          1, 40, 53, 43,  1, 47, 60, 52, 54, 57,  1, 48, 58,  1, 54, 45, 59, 44,\n",
       "         53,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0, 34, 38, 36,  0])}"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds[0] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([200091, 96, 2])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds.data['token_start_offsets'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "original = ds.data['chars_encoded'][3]\n",
    "offsets = ds.data['token_start_offsets'][3]\n",
    "tokens = ds.data['token_ids'][3]\n",
    "num_toks = (tokens!=0).sum()\n",
    "rand_toks = torch.randperm(num_toks)\n",
    "offsets = offsets[rand_toks[:ds.num_masks]]\n",
    "sorted_offsets = torch.sort(offsets, 0)[0]\n",
    "segments_to_keep = torch.cat([ds.beg, sorted_offsets.view(-1), ds.end], 0).view(-1,2)\n",
    "\n",
    "slices = []\n",
    "char_mask = torch.tensor([34,38,36]).char().to('cuda')\n",
    "for start, end in segments_to_keep:\n",
    "  char_slice = original[start:end]\n",
    "  slices.append(char_slice)\n",
    "  slices.append(char_mask)\n",
    "\n",
    "masked_seq = torch.cat(slices, 0)\n",
    "pad_size = max(0, len(original)-len(masked_seq))\n",
    "pad = torch.tensor([0]).expand(pad_size).char().to('cuda')\n",
    "masked_seq = torch.cat([masked_seq, pad], 0)[:len(original)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pad_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Tensor' object has no attribute 'randperm'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-322-7fb3e006f95a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'token_start_offsets'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandperm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'Tensor' object has no attribute 'randperm'"
     ]
    }
   ],
   "source": [
    "original ds.data['token_start_offsets'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a = torch.tensor([[.1,.2,.3,.4,.5]])\n",
    "b = torch.tensor([[.5,.4,.3,.2,.1]])\n",
    "c = torch.tensor([[.1,.1,.1,.1,.5]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def nll(teacher, student):\n",
    "  return -1*(teacher*torch.log(student)).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3.2929)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nll(b,c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class StepWithSigmoidGrad(torch.autograd.Function):\n",
    "    @staticmethod\n",
    "    def forward(self,x):\n",
    "        self.x = x\n",
    "        return (x > 0).float()\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(self,grad_output):\n",
    "        sig = torch.nn.Sigmoid()(self.x)\n",
    "        return sig*(1-sig)\n",
    "\n",
    "class StepWithHardGrad(torch.autograd.Function):\n",
    "    @staticmethod\n",
    "    def forward(self,x):\n",
    "        self.high = (x>-.5) & (x<.5)\n",
    "        return (x > 0).float()\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(self,grad_output):\n",
    "        grad_input = grad_output.clone()\n",
    "        print(self.high)\n",
    "        grad_input[self.high] = 1\n",
    "        grad_input[~self.high] = 0\n",
    "        return grad_input\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "f = StepWithHardGrad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(False)\n",
      "tensor(False)\n",
      "tensor(False)\n",
      "tensor(False)\n",
      "tensor(False)\n",
      "tensor(False)\n",
      "tensor(False)\n",
      "tensor(False)\n",
      "tensor(False)\n",
      "tensor(False)\n",
      "tensor(False)\n",
      "tensor(False)\n",
      "tensor(False)\n",
      "tensor(False)\n",
      "tensor(False)\n",
      "tensor(False)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(True)\n",
      "tensor(False)\n",
      "tensor(False)\n",
      "tensor(False)\n",
      "tensor(False)\n",
      "tensor(False)\n",
      "tensor(False)\n",
      "tensor(False)\n",
      "tensor(False)\n",
      "tensor(False)\n",
      "tensor(False)\n",
      "tensor(False)\n",
      "tensor(False)\n",
      "tensor(False)\n",
      "tensor(False)\n",
      "tensor(False)\n"
     ]
    }
   ],
   "source": [
    "vals = []\n",
    "for i in torch.arange(-2,2,.1):\n",
    "  t = i.clone().detach()\n",
    "  t.requires_grad =True\n",
    "  v = f.apply(t)\n",
    "  v.backward()\n",
    "  vals.append((t.item(), v.item(), t.grad.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(-2.0, 0.0, 0.0),\n",
       " (-1.899999976158142, 0.0, 0.0),\n",
       " (-1.7999999523162842, 0.0, 0.0),\n",
       " (-1.7000000476837158, 0.0, 0.0),\n",
       " (-1.600000023841858, 0.0, 0.0),\n",
       " (-1.5, 0.0, 0.0),\n",
       " (-1.399999976158142, 0.0, 0.0),\n",
       " (-1.2999999523162842, 0.0, 0.0),\n",
       " (-1.2000000476837158, 0.0, 0.0),\n",
       " (-1.100000023841858, 0.0, 0.0),\n",
       " (-1.0, 0.0, 0.0),\n",
       " (-0.8999999761581421, 0.0, 0.0),\n",
       " (-0.800000011920929, 0.0, 0.0),\n",
       " (-0.699999988079071, 0.0, 0.0),\n",
       " (-0.6000000238418579, 0.0, 0.0),\n",
       " (-0.5, 0.0, 0.0),\n",
       " (-0.4000000059604645, 0.0, 1.0),\n",
       " (-0.30000001192092896, 0.0, 1.0),\n",
       " (-0.20000000298023224, 0.0, 1.0),\n",
       " (-0.10000000149011612, 0.0, 1.0),\n",
       " (0.0, 0.0, 1.0),\n",
       " (0.10000000149011612, 1.0, 1.0),\n",
       " (0.20000000298023224, 1.0, 1.0),\n",
       " (0.30000001192092896, 1.0, 1.0),\n",
       " (0.4000000059604645, 1.0, 1.0),\n",
       " (0.5, 1.0, 0.0),\n",
       " (0.6000000238418579, 1.0, 0.0),\n",
       " (0.699999988079071, 1.0, 0.0),\n",
       " (0.800000011920929, 1.0, 0.0),\n",
       " (0.8999999761581421, 1.0, 0.0),\n",
       " (1.0, 1.0, 0.0),\n",
       " (1.100000023841858, 1.0, 0.0),\n",
       " (1.2000000476837158, 1.0, 0.0),\n",
       " (1.2999999523162842, 1.0, 0.0),\n",
       " (1.399999976158142, 1.0, 0.0),\n",
       " (1.5, 1.0, 0.0),\n",
       " (1.600000023841858, 1.0, 0.0),\n",
       " (1.7000000476837158, 1.0, 0.0),\n",
       " (1.7999999523162842, 1.0, 0.0),\n",
       " (1.899999976158142, 1.0, 0.0)]"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "t,v,g = zip(*vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dat1 = {'type':'scatter', 'x':t, 'y':v}\n",
    "dat2 = {'type':'scatter', 'x':t, 'y':g}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/tucker/Downloads/imdb_size_distci.html'"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fig = fig = go.Figure(data=[dat1,dat2])\n",
    "plotly.offline.plot(fig, filename='/home/tucker/Downloads/imdb_size_distci.html')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "argv": [
    "/usr/bin/python3",
    "-m",
    "ipykernel_launcher",
    "-f",
    "{connection_file}"
   ],
   "display_name": "Python 3",
   "env": null,
   "interrupt_mode": "signal",
   "language": "python",
   "metadata": null,
   "name": "python3"
  },
  "name": "ErrorAnalysis.ipynb"
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
