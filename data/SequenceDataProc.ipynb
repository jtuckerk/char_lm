{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tokenizers\n",
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from tokenizers import BertWordPieceTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tokenizer = BertWordPieceTokenizer(\"bert-base-uncased-vocab.txt\",\n",
    "                                   lowercase=True,\n",
    "                                   add_special_tokens=False,\n",
    "                                   clean_text=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lines = []\n",
    "textfile = '/home/tucker/data/imdb/aclImdb/train/unsup_all.txt'\n",
    "#textfile = '/home/tucker/data/news/training-monolingual/news.2007.en.shuffled'\n",
    "with open(textfile) as f:\n",
    "  long_line = f.read().lower().replace('<br /><br />', ' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "TOK_CHUNK_MAX = 58\n",
    "TOK_CHUNK_MIN = 57\n",
    "CHAR_CHUNK_MAX = 384\n",
    "def GetExamplesFromSplitLine(line):\n",
    "  token_ids = []\n",
    "  tokens = line\n",
    "  i = 0\n",
    "  while i*TOK_CHUNK_MAX < len(tokens):\n",
    "    potential = tokens[i*TOK_CHUNK_MAX: (i+1)*TOK_CHUNK_MAX]\n",
    "\n",
    "    if len(potential)>=TOK_CHUNK_MIN:\n",
    "      token_ids.append(\" \".join(potential))\n",
    "    i+=1\n",
    "\n",
    "  return token_ids\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "half = len(long_line)//5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' '"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "long_line[half+5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "long_line = long_line[:half+5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "l=long_line.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "del long_line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "seq_chunks = []\n",
    "\n",
    "t = GetExamplesFromSplitLine(l)\n",
    "for seq in t:\n",
    "  seq_chunks.append(seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "torch.save(seq_chunks, \"tmp.chunks\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "seq_chunks = torch.load(\"tmp.chunks\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "del l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'i admit, the great majority of films released before say 1933 are just not for me. of the dozen or so \"major\" silents i have viewed, one i loved (the crowd), and two were very good (the last command and city lights, that latter chaplin circa 1931). so i was apprehensive about this one, and humor is often'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq_chunks[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200091"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(seq_chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "encoded = tokenizer.encode_batch(seq_chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200091"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "del seq_chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a=encoded[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "token_len = 96\n",
    "char_len = 384"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "idx_to_char_map = {v:k for k,v in torch.load('char_to_idx_map.pt').items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "zerochar = idx_to_char_map[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def GetTokStartOffset(encoded):\n",
    "  offsets = list([x for x in list(zip(*encoded.offsets))[0] if x<char_len])\n",
    "  return offsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "token_list = []\n",
    "char_list = []\n",
    "offset_pos = []\n",
    "for e in encoded:\n",
    "  tokens = e.ids[:token_len]\n",
    "  token_pad = token_len - len(tokens)\n",
    "  tokens += [0]*token_pad\n",
    "\n",
    "  chars = str(e.original_str)[:char_len]\n",
    "  char_pad = char_len - len(chars)\n",
    "  chars += zerochar*char_pad\n",
    "\n",
    "  tok_start_idxs = GetTokStartOffset(e)\n",
    "\n",
    "  offsets = torch.zeros((char_len,))\n",
    "  offsets[tok_start_idxs]= 1\n",
    "\n",
    "  token_list.append(tokens)\n",
    "  char_list.append(chars)\n",
    "  offset_pos.append(offsets)                        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'and turkey, i have never had such a modern and timeless feeling from a silent movie. this results from the cool, timeless acting and characterizations, and the excellent directing and shooting. this is the first silent drammatic film my kids have thoroughly enjoyed, (until now only preferring silent comedic standards by keaton, chaplin, and harold lloyd.) i thought\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "char_list[501]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = {}\n",
    "data['token_ids'] = torch.tensor(token_list).short()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data['chars'] = char_list\n",
    "data['token_start_offsets'] = torch.stack(offset_pos).bool()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "torch.save(data, 'imdb_tok96_char384.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ds = torch.load('imdb_tok96_char384.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "del ds['token_ids']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "torch.save(ds, 'imdb_tok96_char384_no_tok.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ds = torch.load('news2007_tok96_char384_no_tok.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "char_to_idx_map  = torch.load('char_to_idx_map.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "encoded_chars = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for seq in ds['chars']:\n",
    "  enc = []\n",
    "  for c in seq:\n",
    "    enc.append(char_to_idx_map.get(c,0))\n",
    "  encoded_chars.append(enc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "e = torch.tensor(encoded_chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ds['chars_encoded'] = e.char()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "del ds['chars']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "torch.save(ds, 'imdb_tok96_char384_enc_no_tok.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'token_start_offsets': tensor([[ True, False,  True,  ..., False, False, False],\n",
       "         [ True, False, False,  ..., False, False, False],\n",
       "         [ True, False, False,  ..., False, False, False],\n",
       "         ...,\n",
       "         [ True, False, False,  ..., False, False, False],\n",
       "         [ True, False, False,  ..., False, False, False],\n",
       "         [ True, False, False,  ..., False, False, False]]),\n",
       " 'chars_encoded': tensor([[48,  1, 40,  ...,  0,  0,  0],\n",
       "         [43, 48, 45,  ...,  0,  0,  0],\n",
       "         [45, 54, 57,  ...,  0,  0,  0],\n",
       "         ...,\n",
       "         [58, 48, 59,  ...,  0,  0,  0],\n",
       "         [54, 53, 44,  ...,  0,  0,  0],\n",
       "         [58, 54,  1,  ...,  0,  0,  0]], dtype=torch.int8)}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "char_lens = np.array([len(e.original_str) for e in  encoded])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "382.0"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.percentile(char_lens, 98)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "181"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "char_lens.min()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "argv": [
    "/usr/bin/python3",
    "-m",
    "ipykernel_launcher",
    "-f",
    "{connection_file}"
   ],
   "display_name": "Python 3",
   "env": null,
   "interrupt_mode": "signal",
   "language": "python",
   "metadata": null,
   "name": "python3"
  },
  "name": "SequenceDataProc.ipynb"
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
