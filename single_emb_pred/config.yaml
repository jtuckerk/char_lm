experiment_name: single_embedding_prediction
vocab_file: bert-base-uncased-vocab-modmask.txt
char_to_idx_file: char_to_idx_map2.pt
embedding_file: distilbert_embedding_matrix.pt
word_length: 18
hyperparameters:
  word_length:
    - 18
  char_vocab_size:
    - 70
  char_embedding_size:
    - 8
  conv_activation:
    - 'relu'
  seg1_type:
    - 'unfold'
  seg1.kernel_size:
    - 18
  seg2.kernel|filter_sizes:
    - 
      - [1,256]
      - [1,1024]  
      - [1,1024]  
      - [1,12288]
  token_embedding_size:
    - 768
  batch_size:
    - 512
  learning_rate:
    - .000133
  dot_loss_weight:
    - 0
  mse_loss_weight:
    - 100
  loss_fn:
    - 'cos'
  eval_acc:
    - True
  optimizer:
    - 'adam'
  epochs:
    - 50
  space_freq:
    - .5
  lr_step_size:
    - 190700
  lr_decay:
    - 1
  learning_rate_cap:
    - 20
  run_validation:
     - True
  random_seed:
    - 10
  model_size_range_bytes:
    - [0, 1.5e+8]
  end_of_word_loss_weight:
    - 0.0
  add_random_count:
    - 4
  misspelling_rate:
    - 0
  misspelling_transforms:
    - 0
  model_checkpoint:
    - models/c6ce592a5
