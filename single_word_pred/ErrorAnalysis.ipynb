{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[13:56:56] Loaded model: <All keys matched successfully>\n"
     ]
    }
   ],
   "source": [
    "import plotly\n",
    "import plotly.graph_objs as go\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from experiment import Net, InitDataset, CreateModel, LoadCheckpoint\n",
    "from yaml import safe_load\n",
    "import torch.nn as nn\n",
    "\n",
    "exphash = '2b01bedfd'\n",
    "\n",
    "exp = 'results/%s' % exphash\n",
    "with open(exp) as f:\n",
    "  h = safe_load(f.read())\n",
    "h = h['exp_info']  \n",
    "\n",
    "ds = InitDataset(h)\n",
    "\n",
    "\n",
    "model = CreateModel(h['hyperparameters'])\n",
    "LoadCheckpoint(model, 'models/%s'%exphash)\n",
    "\n",
    "model = model.cuda()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ds.add_random_count=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ds.misspelling_rate=None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_loader = DataLoader(ds, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'labels': tensor(0),\n",
       " 'end_of_word_index': tensor(5),\n",
       " 'features': tensor([34, 55, 40, 43, 36,  1, 45, 54, 57, 42, 44,  1])}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'labels': tensor([3000, 3001, 3002, 3003, 3004, 3005, 3006, 3007, 3008, 3009]),\n",
       " 'end_of_word_index': tensor([ 5,  2,  7,  6,  5,  6,  4,  9,  6, 10]),\n",
       " 'features': tensor([[61, 48, 58, 48, 59,  1, 44, 60, 57, 54, 55,  1],\n",
       "         [20, 20,  1,  4,  4, 57, 48, 51, 64,  1,  4,  4],\n",
       "         [44, 61, 44, 53, 48, 53, 46,  1, 59, 57, 40,  1],\n",
       "         [58, 44, 40, 57, 42, 47,  1, 41, 51, 40, 53,  1],\n",
       "         [46, 57, 40, 53, 59,  1, 62, 44, 58, 59,  1, 46],\n",
       "         [44, 45, 45, 54, 57, 59,  1,  4,  4, 42, 40,  1],\n",
       "         [58, 54, 51, 54,  1, 34, 60, 53, 60, 58, 44,  1],\n",
       "         [59, 57, 44, 40, 59, 52, 44, 53, 59,  1,  4,  1],\n",
       "         [41, 60, 57, 48, 44, 43,  1, 34, 60, 53, 60,  1],\n",
       "         [57, 44, 55, 60, 41, 51, 48, 42, 40, 53,  1,  1]])}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds[3000:3010]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "xent = nn.CrossEntropyLoss(reduction='none')\n",
    "def xentropy_loss_fn(output, labels):\n",
    "  return xent(output.view(-1, output.size(-1)), labels.view(-1))\n",
    "\n",
    "def acc_fn(output, labels):\n",
    "  top = output.argmax(-1)\n",
    "  right = top==labels\n",
    "  return right.float()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Torch2Py = lambda x: x.cpu().numpy().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def Validate(val_loader, model):\n",
    "  device = next(model.parameters()).device\n",
    "\n",
    "  cum_acc = 0\n",
    "  cum_xent_loss = 0\n",
    "\n",
    "  inputs_ = []\n",
    "  right_ = []\n",
    "  losses_ = []\n",
    "  maxes = []\n",
    "  for i, data in enumerate(val_loader):\n",
    "    data = {k: d.to(device) for k,d in data.items()}\n",
    "    inputs = data['features'].to(device)\n",
    "    labels = data['labels'].long()\n",
    "    inputs_ += Torch2Py(inputs)\n",
    "    with torch.no_grad():\n",
    "      outputs = model(inputs)\n",
    "      maxes += Torch2Py(outputs.argmax(-1))\n",
    "      xent_loss = xentropy_loss_fn(outputs, labels)\n",
    "      losses_ += Torch2Py(xent_loss)\n",
    "      cum_xent_loss += xent_loss.mean()\n",
    "\n",
    "      acc = acc_fn(outputs, labels)\n",
    "      right_ += Torch2Py(acc)\n",
    "      cum_acc += acc.mean()\n",
    "  print(cum_acc/(i+1), cum_xent_loss/(i+1))\n",
    "  return inputs_, right_, losses_, maxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.9966, device='cuda:0') tensor(0.0110, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "ip, right, losses, maxes = Validate(train_loader, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28452, 28452, 28452, 28452)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ip), len(right), len(losses), len(maxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "idx_to_char_map= {v:k for k,v in ds.char_to_idx_map.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def GetChars(encoded):\n",
    "  s = \"\"\n",
    "  for c in encoded:\n",
    "    s+= idx_to_char_map[c]\n",
    "  return s.replace('\\x00','_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'labels': tensor(0),\n",
       " 'end_of_word_index': tensor(5),\n",
       " 'features': tensor([34, 55, 40, 43, 36,  1, 54, 41, 58, 59, 57,  1])}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ds.add_random_count=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "999"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "maxes[999]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1013 |/ needles [u /___________ sentences___\n",
      "1021 |7 lined coun 7___________ ##lined_____\n",
      "1030 |@ proper ##s @___________ improper____\n",
      "1035 |_ privatiza  ____________ deprivation_\n",
      "1036 |` galicia ac `___________ highlight___\n",
      "1038 |b sergio ing b___________ bose________\n",
      "1051 |p ##rad [unu p___________ (___________\n",
      "1527 |development  development_ developments\n",
      "1594 |##ra fists j ##ra________ ##ra_e______\n",
      "2045 |independent  independent_ independents\n",
      "2214 |traditional  traditional_ traditionall\n",
      "2218 |approximate  approximatel approximate_\n",
      "2311 |municipalit  municipality municipaliti\n",
      "2338 |significant  significant_ significantl\n",
      "2898 |corporation  corporation_ corporations\n",
      "3128 |account ng # account_____ accounting__\n",
      "3252 |participate  participated participate_\n",
      "3352 |architectur  architecture architectura\n",
      "3666 |performance  performances performance_\n",
      "3822 |publication  publication_ publications\n",
      "3943 |institution  institutions institutiona\n",
      "4142 |application  applications application_\n",
      "4145 |incorporate  incorporated incorporates\n",
      "4189 |institution  institution_ institutiona\n",
      "4391 |juan mcpher  juan________ quan________\n",
      "4428 |partnership_ partnership_ partnerships\n",
      "4581 |constituenc  constituency constituenci\n",
      "4955 |requirement  requirements requirement_\n",
      "5135 |appointment  appointment_ appointments\n",
      "5188 |alfred______ alfred______ alfredo_____\n",
      "5232 |considerabl  considerable considerably\n",
      "5378 |achievement  achievement_ achievements\n",
      "5396 |_ ##ar bind_ _c__________ _1__________\n",
      "5406 |legislature  legislature_ legislatures\n",
      "5422 |experimenta  experimental experimentat\n",
      "5446 |description  description_ descriptions\n",
      "5447 |appropriate  appropriate_ appropriated\n",
      "5512 |competition  competitions competition_\n",
      "5608 |participatio participatio participatin\n",
      "5880 |unfortunate  unfortunatel unfortunate_\n",
      "6424 |celebration  celebration_ celebrations\n",
      "6569 |preparation  preparation_ preparations\n",
      "6587 |arrangement  arrangements arrangement_\n",
      "6665 |demonstrate  demonstrated demonstrate_\n",
      "6735 |temperature  temperatures temperature_\n",
      "6741 |comprehensi  comprehensiv comprehensio\n",
      "6792 |negotiation  negotiations negotiation_\n",
      "6796 |inspiration  inspiration_ inspirationa\n",
      "6914 |instruction  instruction_ instructions\n",
      "7065 |fundamental  fundamental_ fundamentall\n",
      "7103 |observation  observation_ observations\n",
      "7171 |_ theologia  _f__________ _2__________\n",
      "7210 |certificate  certificate_ certificates\n",
      "7290 |concentrate  concentrated concentrate_\n",
      "7564 |investigate  investigate_ investigated\n",
      "7653 |predecessor  predecessor_ predecessors\n",
      "7740 |reconstruct  reconstructi reconstructe\n",
      "7925 |association  associations association_\n",
      "7970 |acknowledge  acknowledged acknowledges\n",
      "7987 |nationalist  nationalist_ nationalists\n",
      "8175 |independent  independentl independents\n",
      "8198 |predominant  predominantl predominant_\n",
      "8265 |composition  compositions composition_\n",
      "8302 |palestinian  palestinian_ palestinians\n",
      "8315 |inscription  inscription_ inscriptions\n",
      "8373 |theoretical  theoretical_ theoreticall\n",
      "8403 |headquarter  headquartere headquarters\n",
      "8509 |consequence  consequence_ consequences\n",
      "8665 |philosopher  philosopher_ philosophers\n",
      "8919 |manufacture  manufacture_ manufactured\n",
      "9054 |environment  environments environment_\n",
      "9260 |interaction  interactions interaction_\n",
      "9630 |communicate  communicate_ communicated\n",
      "9890 |measurement  measurement_ measurements\n",
      "9895 |expectation  expectations expectation_\n",
      "10064 |reservation  reservation_ reservations\n",
      "10285 |surroundings surroundings surrounding_\n",
      "10789 |exceptional  exceptional_ exceptionall\n",
      "10793 |transaction  transactions transaction_\n",
      "10888 |translation  translations translation_\n",
      "11103 |contributor  contributor_ contributors\n",
      "11240 |commentator  commentator_ commentators\n",
      "11289 |collaborati  collaborativ collaboratin\n",
      "11353 |substantial  substantiall substantial_\n",
      "11543 |subdivision_ subdivision_ subdivisions\n",
      "11567 |comparative  comparative_ comparativel\n",
      "12146 |participant  participant_ participants\n",
      "12230 |incorporate  incorporate_ incorporates\n",
      "12363 |acknowledge_ acknowledge_ acknowledges\n",
      "12379 |commemorate  commemorate_ commemorated\n",
      "12458 |implication  implications implication_\n",
      "12600 |counterpart  counterpart_ counterparts\n",
      "12756 |constituent_ constituent_ constituents\n",
      "12869 |development  developmenta developments\n",
      "13042 |alternativel alternativel alternatives\n",
      "13298 |destination  destinations destination_\n",
      "13857 |examination  examinations examination_\n",
      "13875 |combination  combinations combination_\n",
      "13970 |investigati  investigativ investigatin\n",
      "14192 |perspective  perspectives perspective_\n",
      "14214 |compartment  compartment_ compartments\n",
      "14276 |shareholder  shareholders shareholder_\n",
      "14625 |scholarship  scholarships scholarship_\n",
      "14887 |alternative  alternatives alternative_\n",
      "15198 |calculation  calculations calculation_\n",
      "15300 |assassinate  assassinated assassinate_\n",
      "15560 |distributor  distributor_ distributors\n",
      "15610 |contemporar  contemporari contemporary\n",
      "15619 |demonstrate  demonstrates demonstrate_\n",
      "15768 |restriction  restriction_ restrictions\n",
      "15860 |incorporati  incorporatio incorporatin\n",
      "15930 |supermarket  supermarket_ supermarkets\n",
      "16177 |participate  participates participate_\n",
      "16411 |##_ monterr  ##_e________ ##_a________\n",
      "16436 |commemorati  commemorativ commemoratio\n",
      "16541 |spontaneous  spontaneous_ spontaneousl\n",
      "16570 |scandinavia  scandinavian scandinavia_\n",
      "16869 |explanation  explanations explanation_\n",
      "17130 |psycho alps  psycho______ psyche______\n",
      "17607 |broadcaster  broadcasters broadcaster_\n",
      "18417 |acquisition  acquisitions acquisition_\n",
      "18590 |##_a haunti  ##_aw_______ ##_a________\n",
      "19401 |progressive  progressivel progressive_\n",
      "19526 |commemorati  commemoratin commemoratio\n",
      "19731 |distinguish  distinguishi distinguish_\n",
      "19759 |collaborate  collaborate_ collaborated\n",
      "20126 |intentional  intentional_ intentionall\n",
      "20241 |northampton  northamptons northampton_\n",
      "20248 |coefficient  coefficients coefficient_\n",
      "20421 |##wai defin  ##wai_______ ##wal_______\n",
      "20725 |_ publicl in _2__________ _1__________\n",
      "20802 |##_ enchant  ##_s________ ##_i________\n",
      "20859 |protagonist  protagonists protagonist_\n",
      "20897 |manufacture  manufactures manufactured\n",
      "21080 |synthesizer  synthesizers synthesizer_\n",
      "21203 |computation  computation_ computationa\n",
      "21562 |expenditure  expenditures expenditure_\n",
      "21567 |39th tnt all 39th________ 39__________\n",
      "21619 |compilation  compilations compilation_\n",
      "21836 |##_ [unused  ##_a________ ##_e________\n",
      "22053 |characteriz  characteriza characterize\n",
      "22081 |instruction  instructiona instructions\n",
      "22125 |appropriate  appropriatel appropriated\n",
      "22790 |replacement  replacements replacement_\n",
      "23386 |disturbance  disturbances disturbance_\n",
      "23478 |confederate  confederates confederate_\n",
      "23783 |consolidate  consolidate_ consolidated\n",
      "24369 |commemorate  commemorates commemorated\n",
      "24795 |controversi  controversie controversia\n",
      "24828 |distinction  distinctions distinction_\n",
      "25120 |transmitter  transmitters transmitter_\n",
      "25502 |designation  designations designation_\n",
      "25852 |supplemental supplemental supplementar\n",
      "26510 |##_ joho acc ##_y________ ##_e________\n",
      "26634 |_ ##elle wag _5__________ _f__________\n",
      "26706 |ob deliver a ob__________ or__________\n",
      "26882 |investigate  investigates investigated\n",
      "27002 |_ desire ##b _3__________ redesign____\n",
      "27141 |demographic  demographics demographic_\n",
      "27259 |deteriorati  deterioratin deterioratio\n",
      "27777 |accommodate  accommodated accommodate_\n",
      "27842 |pau asks ##p pau_________ caucasus____\n",
      "28444 |##] blazed a ##]_________ ##@_________\n"
     ]
    }
   ],
   "source": [
    "for i, r in enumerate(right):\n",
    "  if r==0:\n",
    "    print(i, \"|\"+GetChars(ip[i]), GetChars(Torch2Py(ds[i]['features'])), GetChars(Torch2Py(ds[maxes[i]]['features'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "argv": [
    "/usr/bin/python3",
    "-m",
    "ipykernel_launcher",
    "-f",
    "{connection_file}"
   ],
   "display_name": "Python 3",
   "env": null,
   "interrupt_mode": "signal",
   "language": "python",
   "metadata": null,
   "name": "python3"
  },
  "name": "ErrorAnalysis.ipynb"
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
