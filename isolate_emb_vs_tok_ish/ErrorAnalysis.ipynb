{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import plotly\n",
    "import plotly.graph_objs as go\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from experiment import Net, InitDataset, CreateModel, LoadCheckpoint, RunOne\n",
    "from yaml import safe_load\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#good chars: dfb53a6b2\n",
    "#perfect emb: a2bb6c3c8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "exphash = 'dfb53a6b2'\n",
    "exp = 'results/%s' % exphash\n",
    "with open(exp) as f:\n",
    "  h = safe_load(f.read())\n",
    "h = h['exp_info']  \n",
    "\n",
    "ds = InitDataset(h)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[13:22:55] loading configuration file bert_distil_uncased/config.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[13:22:55] loading weights file bert_distil_uncased/pytorch_model.bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[13:22:56] Loaded model: _IncompatibleKeys(missing_keys=['LayerNorm.weight', 'LayerNorm.bias'], unexpected_keys=[])\n"
     ]
    }
   ],
   "source": [
    "#h['hyperparameters']['manual_attention'] = True\n",
    "model = CreateModel(h['hyperparameters'])\n",
    "LoadCheckpoint(model, 'models/%s'%exphash)\n",
    "\n",
    "model = model.cuda()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "h['dataset_split'][1] = .01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "val_loader = DataLoader(ds[1], batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'label_ids': tensor([23244,  2075,  1037,  4284,  2003,  1996,  3287,  7866,  1996,  2931,\n",
       "          1998,  1996,  3588,  4284,  2108,  3801,  7866,  2037,  3287,  4256,\n",
       "         12515,  2129,  2116, 12107,  1997,  4968,  4808,  2941,  9125,  3287,\n",
       "          5694,  2003,  3697,  3287,  4968,  4808,  5694,  2089,  2022, 11542,\n",
       "          2000,  2131,  2393,  2005,  1037,  2193,  1997,  4436,  2156,  2023,\n",
       "          3720,  3720,  7039,  2257,  2809,  2048,  5717,  5717,  2176,  1037,\n",
       "          2158,  2040,  4455,  2005,  2393,  2089,  2130,  3891,  2108,  4727,\n",
       "          2004,  1996,  2566, 22327, 16259,  2130,  2295,  2002,  2001,  1996,\n",
       "          6778,  1996,  2236, 10465,  3849,  2000,  2022,  2008,  3287,  2006,\n",
       "          2931,  4968,  4808,  2003,  2062,  3497], device='cuda:0'),\n",
       " 'input_ids': tensor([[32, 56, 33,  ...,  0,  0,  0],\n",
       "         [52, 57, 50,  ...,  0,  0,  0],\n",
       "         [44,  0,  0,  ...,  0,  0,  0],\n",
       "         ...,\n",
       "         [52, 62,  0,  ...,  0,  0,  0],\n",
       "         [56, 58, 61,  ...,  0,  0,  0],\n",
       "         [55, 52, 54,  ...,  0,  0,  0]], device='cuda:0'),\n",
       " 'token_ids': tensor([  103,  2075,  1037,  4284,  2003,  1996,  3287,  7866,  1996,  2931,\n",
       "          1998,  1996,   103,  4284,  2108,  3801,  7866,  2037,  3287,  4256,\n",
       "         12515,  2129,   103, 12107,  1997,  4968,  4808,  2941,  9125,  3287,\n",
       "          5694,  2003,  3697,  3287,  4968,  4808,  5694,  2089,  2022, 11542,\n",
       "          2000,  2131,  2393,  2005,  1037,  2193,  1997,  4436,   103,  2023,\n",
       "          3720,  3720,  7039,  2257,  2809,  2048,  5717,  5717,  2176,  1037,\n",
       "          2158,  2040,  4455,  2005,  2393,   103,   103,  3891,  2108,  4727,\n",
       "          2004,  1996,  2566, 22327, 16259,  2130,  2295,  2002,  2001,  1996,\n",
       "          6778,  1996,   103, 10465,  3849,  2000,  2022,  2008,  3287,  2006,\n",
       "          2931,  4968,  4808,  2003,  2062,  3497], device='cuda:0')}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds[1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "char_to_idx_map = torch.load('../data/char_to_idx_map2.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Torch2Py = lambda x: x.cpu().numpy().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "idx_to_char_map= {v:k for k,v in char_to_idx_map.items()}\n",
    "idx_to_tok_map = {}\n",
    "with open('../data/bert-base-uncased-vocab.txt') as f:\n",
    "  for i, l in enumerate(f.readlines()):\n",
    "    idx_to_tok_map[i] = l.strip()\n",
    "def GetChars(encoded):\n",
    "  s = \"\"\n",
    "  for c in encoded:\n",
    "    s+= idx_to_char_map[c]\n",
    "  return s.replace('\\x00','_')\n",
    "def GetToks(encoded):\n",
    "  s = \"\"\n",
    "  for c in encoded:\n",
    "    s+= \" \" + idx_to_tok_map[c]\n",
    "  return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41\n"
     ]
    }
   ],
   "source": [
    "w = '[cls] guitars [m] some ot [m] [pad] [pad]'\n",
    "thing = []\n",
    "for c in w :\n",
    "  thing.append(char_to_idx_map[c])\n",
    "print(len(thing))\n",
    "inp = torch.tensor(thing).unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[32, 46, 55, 62, 33,  1, 50, 64, 52, 63, 44, 61, 62,  1, 32, 56, 33,  1,\n",
       "         62, 58, 56, 48,  1, 58, 63,  1, 32, 56, 33,  1, 32, 59, 44, 47, 33,  1,\n",
       "         32, 59, 44, 47, 33]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "inp_ids = ds[1][0]['input_ids'].unsqueeze(0)\n",
    "label_ids = ds[1][0]['label_ids']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "token_ids = ds[1][0]['token_ids'].unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[m]_______________\n",
      "ing_______________\n",
      "a_________________\n",
      "quarter___________\n",
      "is________________\n",
      "the_______________\n",
      "male______________\n",
      "attacking_________\n",
      "the_______________\n",
      "female____________\n",
      "and_______________\n",
      "the_______________\n",
      "remaining_________\n",
      "[m]_______________\n",
      "[m]_______________\n",
      "females___________\n",
      "attacking_________\n",
      "their_____________\n",
      "male______________\n",
      "partner___________\n",
      "[m]_______________\n",
      "how_______________\n",
      "many______________\n",
      "instances_________\n",
      "of________________\n",
      "domestic__________\n",
      "[m]_______________\n",
      "actually__________\n",
      "involve___________\n",
      "male______________\n",
      "victims___________\n",
      "is________________\n",
      "difficult_________\n",
      "[m]_______________\n",
      "domestic__________\n",
      "violence__________\n",
      "victims___________\n",
      "may_______________\n",
      "be________________\n",
      "reluctant_________\n",
      "to________________\n",
      "get_______________\n",
      "help______________\n",
      "for_______________\n",
      "a_________________\n",
      "number____________\n",
      "of________________\n",
      "[m]_______________\n",
      "see_______________\n",
      "this______________\n",
      "article___________\n",
      "article___________\n",
      "checked___________\n",
      "august____________\n",
      "eight_____________\n",
      "two_______________\n",
      "zero______________\n",
      "zero______________\n",
      "four______________\n",
      "a_________________\n",
      "man_______________\n",
      "who_______________\n",
      "calls_____________\n",
      "for_______________\n",
      "help______________\n",
      "may_______________\n",
      "even______________\n",
      "[m]_______________\n",
      "[m]_______________\n",
      "arrested__________\n",
      "as________________\n",
      "[m]_______________\n",
      "[m]_______________\n",
      "pet_______________\n",
      "rator_____________\n",
      "even______________\n",
      "though____________\n",
      "he________________\n",
      "was_______________\n",
      "the_______________\n",
      "victim____________\n",
      "the_______________\n",
      "general___________\n",
      "consensus_________\n",
      "seems_____________\n",
      "[m]_______________\n",
      "[m]_______________\n",
      "that______________\n",
      "[m]_______________\n",
      "on________________\n",
      "female____________\n",
      "domestic__________\n",
      "[m]_______________\n",
      "is________________\n",
      "more______________\n",
      "likely____________\n"
     ]
    }
   ],
   "source": [
    "for i in inp_ids[0]:\n",
    "  print(GetChars(Torch2Py(i)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' brawl ##ing a quarter is the male attacking the female and the remaining quarter being females attacking their male partner determining how many instances of domestic violence actually involve male victims is difficult male domestic violence victims may be reluctant to get help for a number of reasons see this article article checked august eight two zero zero four a man who calls for help may even risk being arrested as the per ##pet ##rator even though he was the victim the general consensus seems to be that male on female domestic violence is more likely'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GetToks(Torch2Py(label_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 96, 18])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp_ids.shape #chars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "output = model(inp_ids.cuda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "moutwords = output.argmax(-1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' . \" a quarter is the male attacking the female and the female male male males attacking their male partner . how many instances of sexual violence actually multiple male victims are difficult romance domestic violence victims may be interested to please help please a number of please see from article article contents august eight two zero zero four a man and calls for help may , child victims arrested as male male pet ##rator even though he was the victim the general consensus seems . conclusion that assault on female domestic violence is more likely'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# gives a garbage output\n",
    "GetToks(Torch2Py(moutwords))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# we check the inputs that are put into  the distilbert model (assumption maybe wrong) ---hold on\n",
    "inp_embs = model.bert.distilbert.inputs_embeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' [CLS] ##ing a quarter is the male 910 the ##dna and the remaining [CLS] [CLS] ##dna ##rdon their male partner [CLS] how 690 ##rdon of domestic [CLS] 930 ##omba male victims is 670 [CLS] domestic ##omba victims may 243 ##hner to get help for a number of [CLS] see this article article checked 740 820 two zero zero 276 a 243 who calls for help may even [CLS] [CLS] ##anor as [CLS] [CLS] pet ##rator even though 670 was the ##anor the general consensus ##anor [CLS] [CLS] that [CLS] on ##dna domestic [CLS] 930 more likely'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# with and without position embeddings we for the most part get the word back checking this way.\n",
    "inp_embs = model.embedded_chars\n",
    "#inp_embs = model.embedded_chars_no_pos\n",
    "word = (inp_embs@model.bert.distilbert.embeddings.word_embeddings.weight.data.T).argmax(-1)[0]\n",
    "GetToks(Torch2Py(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " one the one quarter is the male attacking the victim and the remaining quarter being female male the male partner . how many instances of domestic violence actually involve male victims is difficult male domestic violence victims may be reluctant to get help for a variety of reasons see this article article checked august eight two zero zero four a man who calls for help may even consider being identified as the per ##pet ##rator even though he was the victim the general consensus seems to be that focusing on female domestic violence is more likely\n",
      "AA\n",
      " romance romance romance romance romance romance romance romance romance romance romance romance romance romance romance romance romance romance romance romance romance romance romance romance romance romance romance romance romance romance romance romance romance romance romance romance romance romance romance romance romance romance romance romance romance romance romance romance romance romance romance romance romance romance romance romance romance romance romance romance romance romance romance romance romance romance romance romance romance romance romance romance romance romance romance romance romance romance romance romance romance romance romance romance romance romance romance romance romance romance romance romance romance romance romance romance\n"
     ]
    }
   ],
   "source": [
    "# giving the model the token ids directly we get good results as expected. this is vanilla bert.\n",
    "outputstok = model.bert(input_ids=token_ids)\n",
    "tokoutwords = outputstok[0].argmax(-1)[0]\n",
    "print(GetToks(Torch2Py(tokoutwords)))\n",
    "\n",
    "# so if we run this and grab the input embeddings just before they go into the transformer\n",
    "inp_emb_tok_pos = model.bert.distilbert.inputs_embeds\n",
    "inp_emb_tok_no_pos = model.bert.distilbert.inputs_embeds_no_pos\n",
    "outputstok = model.bert(inputs_embeds=inp_emb_tok_no_pos)\n",
    "tokoutwords = outputstok[0].argmax(-1)[0]\n",
    "print(\"AA\")\n",
    "print(GetToks(Torch2Py(tokoutwords)))\n",
    "# no pos gives garbage\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' brawl ##ing [CLS] quarter is the male ##rdon the [CLS] and [CLS] remaining quarter being females [CLS] [CLS] male partner [CLS] how many ##rdon of domestic ##anor 670 [CLS] male ##anor is 670 male domestic ##anor ##anor may be ##rdon to 930 help for a number of reasons see this article article ##rdon 740 840 two zero zero 276 a man who calls for help may even [CLS] being [CLS] as the per [CLS] ##rator even though 670 was the ##dna the general consensus ##anor to be that [CLS] on 690 domestic ##anor is [CLS] likely'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking the result of looking at the input embeddings when compared directly with the emb matrix shows similar to the char predembs\n",
    "out = model.bert.distilbert.inputs_embeds_no_pos\n",
    "word = (out@model.bert.distilbert.embeddings.word_embeddings.weight.data.T).argmax(-1)[0]\n",
    "GetToks(Torch2Py(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pos_emb' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mNameError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-dc8d20b402bf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0minp_embs_no_pos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedded_chars_no_pos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0minp_embs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedded_chars\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0moutputsemb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs_embeds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minp_embs\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mpos_emb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0mcharoutwords\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutputsemb\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mGetToks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTorch2Py\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcharoutwords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pos_emb' is not defined"
     ]
    }
   ],
   "source": [
    "# if we input the embeddings from the char embedder with and without pos what happens?\n",
    "# without pos its garbage just ------- across the board.\n",
    "# with pos its basically the same but with a single . instead of all - - -\n",
    "\n",
    "# BUG: adding the position embeddings from the vanilla bert model gives the right output. so im just adding the pos embeddings wrong in my experiments.\n",
    "# i wonder if theyre getting initialized to new values when the model initializes?!\n",
    "output = model(inp_ids.cuda())\n",
    "\n",
    "inp_embs_no_pos = model.embedded_chars_no_pos\n",
    "inp_embs = model.embedded_chars\n",
    "outputsemb = model.bert(inputs_embeds=inp_embs+pos_emb)\n",
    "charoutwords = outputsemb[0].argmax(-1)[0]\n",
    "print(GetToks(Torch2Py(charoutwords)))\n",
    "print()\n",
    "charoutwords = output[0].argmax(-1)\n",
    "print(GetToks(Torch2Py(charoutwords)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1., device='cuda:0')"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# so the position embeddings are correct...\n",
    "(model.pos_emb_inst == model.bert.distilbert.embeddings.position_embeddings_inst).float().mean()\n",
    "# FAAAACK I FORGOT THE LAYER NORM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1.7505e-02, -2.5631e-02, -3.6642e-02,  ...,  3.3437e-05,\n",
       "           6.8312e-04,  1.5441e-02],\n",
       "         [ 7.7580e-03,  2.2613e-03, -1.9444e-02,  ...,  2.8910e-02,\n",
       "           2.9753e-02, -5.3247e-03],\n",
       "         [-1.1287e-02, -1.9644e-03, -1.1573e-02,  ...,  1.4908e-02,\n",
       "           1.8741e-02, -7.3140e-03],\n",
       "         ...,\n",
       "         [ 1.0013e-03, -1.8523e-03,  6.4189e-03,  ..., -7.2757e-03,\n",
       "           1.7281e-03,  2.8407e-03],\n",
       "         [-3.6395e-03,  8.9983e-03,  1.3761e-02,  ..., -3.5218e-03,\n",
       "           3.5612e-04,  7.9451e-03],\n",
       "         [-1.8650e-02,  7.7867e-03,  1.8862e-02,  ..., -1.9309e-02,\n",
       "           2.0698e-02,  9.4798e-03]]], device='cuda:0',\n",
       "       grad_fn=<EmbeddingBackward>)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 1.7505e-02, -2.5631e-02, -3.6642e-02,  ...,  3.3437e-05,\n",
       "          6.8312e-04,  1.5441e-02],\n",
       "        [ 7.7580e-03,  2.2613e-03, -1.9444e-02,  ...,  2.8910e-02,\n",
       "          2.9753e-02, -5.3247e-03],\n",
       "        [-1.1287e-02, -1.9644e-03, -1.1573e-02,  ...,  1.4908e-02,\n",
       "          1.8741e-02, -7.3140e-03],\n",
       "        ...,\n",
       "        [ 1.7418e-02,  3.4903e-03, -9.5621e-03,  ...,  2.9599e-03,\n",
       "          4.3435e-04, -2.6949e-02],\n",
       "        [ 2.1687e-02, -6.0216e-03,  1.4736e-02,  ..., -5.6118e-03,\n",
       "         -1.2590e-02, -2.8085e-02],\n",
       "        [ 2.6413e-03, -2.3298e-02,  5.4922e-03,  ...,  1.7537e-02,\n",
       "          2.7550e-02, -7.7656e-02]], device='cuda:0', requires_grad=True)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.position_embeddings.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 1.7505e-02, -2.5631e-02, -3.6642e-02,  ...,  3.3437e-05,\n",
       "          6.8312e-04,  1.5441e-02],\n",
       "        [ 7.7580e-03,  2.2613e-03, -1.9444e-02,  ...,  2.8910e-02,\n",
       "          2.9753e-02, -5.3247e-03],\n",
       "        [-1.1287e-02, -1.9644e-03, -1.1573e-02,  ...,  1.4908e-02,\n",
       "          1.8741e-02, -7.3140e-03],\n",
       "        ...,\n",
       "        [ 1.7418e-02,  3.4903e-03, -9.5621e-03,  ...,  2.9599e-03,\n",
       "          4.3435e-04, -2.6949e-02],\n",
       "        [ 2.1687e-02, -6.0216e-03,  1.4736e-02,  ..., -5.6118e-03,\n",
       "         -1.2590e-02, -2.8085e-02],\n",
       "        [ 2.6413e-03, -2.3298e-02,  5.4922e-03,  ...,  1.7537e-02,\n",
       "          2.7550e-02, -7.7656e-02]], device='cuda:0', requires_grad=True)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.bert.distilbert.embeddings.position_embeddings.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
       "         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
       "         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n",
       "         54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71,\n",
       "         72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89,\n",
       "         90, 91, 92, 93, 94, 95]], device='cuda:0')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.position_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "word = ((out[0, :8].unsqueeze(1)-model.bert.distilbert.embeddings.word_embeddings.weight.data)**2).mean(-1).argmin(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' purpose article two [MASK] of scientific investigation and'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GetToks(Torch2Py(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pos_emb = inp_emb_tok_pos - inp_emb_tok_no_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "argv": [
    "/usr/bin/python3",
    "-m",
    "ipykernel_launcher",
    "-f",
    "{connection_file}"
   ],
   "display_name": "Python 3",
   "env": null,
   "interrupt_mode": "signal",
   "language": "python",
   "metadata": null,
   "name": "python3"
  },
  "name": "ErrorAnalysis.ipynb"
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
