{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[16:24:28] loading configuration file bert_distil_uncased/config.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[16:24:28] loading weights file bert_distil_uncased/pytorch_model.bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[16:24:30] Loaded model: <All keys matched successfully>\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import plotly\n",
    "import plotly.graph_objs as go\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from experiment import Net, InitDataset, CreateModel, LoadCheckpoint\n",
    "from yaml import safe_load\n",
    "import torch.nn as nn\n",
    "\n",
    "exphash = '6c82028bc'\n",
    "\n",
    "exp = 'results/%s' % exphash\n",
    "with open(exp) as f:\n",
    "  h = safe_load(f.read())\n",
    "h = h['exp_info']  \n",
    "\n",
    "ds = InitDataset(h)\n",
    "\n",
    "#h['hyperparameters']['manual_attention'] = True\n",
    "model = CreateModel(h['hyperparameters'])\n",
    "LoadCheckpoint(model, 'models/%s'%exphash)\n",
    "\n",
    "model = model.cuda()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "h['dataset_split'][1] = .01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "val_loader = DataLoader(ds[1], batch_size=64, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Torch2Py = lambda x: x.cpu().numpy().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "xent = nn.CrossEntropyLoss()\n",
    "def xentropy_loss_fn(output, labels):\n",
    "  return xent(output.view(-1, output.size(-1)), labels.view(-1))\n",
    "\n",
    "def top1_acc_fn(output, labels):\n",
    "  top = output.argmax(-1)\n",
    "  right = top==labels\n",
    "  return right.float()\n",
    "\n",
    "def Validate(val_loader, model):\n",
    "  cum_acc = 0\n",
    "  cum_xent_loss = 0\n",
    "\n",
    "  rights_ = []\n",
    "  inputs_ =[]\n",
    "  labels_ =[]\n",
    "  maxes_ =[]\n",
    "  for i, data in enumerate(val_loader):\n",
    "    inputs = data['input_ids']\n",
    "    labels = data['label_ids']\n",
    "    inputs_ += Torch2Py(inputs)\n",
    "    labels_ += Torch2Py(labels)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "      model.eval()\n",
    "      outputs = model(inputs)\n",
    "      maxes_ += Torch2Py(outputs.argmax(-1))\n",
    "      xent_loss = xentropy_loss_fn(outputs, labels)\n",
    "      cum_xent_loss += xent_loss      \n",
    "\n",
    "      top1_acc = top1_acc_fn(outputs, labels)\n",
    "      rights_ += Torch2Py(top1_acc)\n",
    "      cum_acc += top1_acc.mean()\n",
    "    if len(inputs_)>100:\n",
    "      break\n",
    "\n",
    "  steps = i+1\n",
    "  print(cum_acc/steps, cum_xent_loss.detach()/steps)\n",
    "  return rights_, inputs_, labels_, maxes_,\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0125, device='cuda:0') tensor(9.7464, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "right, inputs, labels, maxes = Validate(val_loader, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(128, 128, 128, 128)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(right), len(inputs), len(labels), len(maxes),"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([96, 768])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.embedded_chars[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "char_to_idx_map = torch.load('../data/char_to_idx_map.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "idx_to_char_map= {v:k for k,v in char_to_idx_map.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "idx_to_tok_map = {}\n",
    "with open('../data/bert-base-uncased-vocab.txt') as f:\n",
    "  for i, l in enumerate(f.readlines()):\n",
    "    idx_to_tok_map[i] = l.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def GetChars(encoded):\n",
    "  s = \"\"\n",
    "  for c in encoded:\n",
    "    s+= idx_to_char_map[c]\n",
    "  return s.replace('\\x00','_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def GetToks(encoded):\n",
    "  s = \"\"\n",
    "  for c in encoded:\n",
    "    s+= \" \" + idx_to_tok_map[c]\n",
    "  return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "inps = ds[0][0:3]['input_ids']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "  a = ((model.embedded_chars[0, 0:8, :].unsqueeze(1)-model.bert.distilbert.embeddings.word_embeddings.weight.data)**2).mean(-1).argmin(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "  a = (model.embedded_chars[:3, 0:20, :].unsqueeze(1)@model.bert.distilbert.embeddings.word_embeddings.weight.data.T).argmax(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[cls] so off the wall and hilarious. you would never expect that guys moving around action figures to do things would be hilarious, but it really is. this is honestly one of the best shows adult swim has put out since they began to air shows like space ghost coast to coast and family guy. creators, including seth green________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "print(GetChars(inputs[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [CLS] dax / so off the wall and hilarious ; you would never expect that guys moving around action figures ##ta do high would ##b ##hul 2 - ##i ##dda ##isa ##i [CLS] ##ys ##hosh ##ld ##oth ##oth ##ayo ##bes show shah ##sz pas put put ##oud pei ##kle ##dna ##oe ##sio auschwitz 3 horn coast go ##jo ##jas bat tao 3 2 2 2 2 57 greens green ##pw ##wy ##wy ##wy ##wy ##wy ##wy ##wy ##wy ##wy ##wy ##wy ##wy ##wy ##wy ##wy ##wy ##wy ##wy ##wy ##wy ##wy ##wy ##wy ##wy ##wy ##wy\n"
     ]
    }
   ],
   "source": [
    "print(GetToks(maxes[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "embeddings = ds.data['embeddings']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.6638, device='cuda:0')"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings.norm(2,-1).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "embedding_noise = .25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "r = torch.normal(mean=embedding_noise, std=1, size=embeddings.size()).cuda()\n",
    "norm_factor = torch.norm(r, 2, -1).mean()/embedding_noise\n",
    "normalized_noise = r/norm_factor\n",
    "new = embeddings + normalized_noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(8.1433e-05, device='cuda:0')"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "((new-embeddings)**2).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0072, device='cuda:0')"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sqrt((new-embeddings)**2).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n = new.norm(2,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def MakeHist(h, name=None):\n",
    "  y = h[0]\n",
    "  x= h[1]\n",
    "  return {\n",
    "    'name': name,\n",
    "    'type': 'bar',                                                                                                                   'x': x,\n",
    "          'marker': dict(opacity=.7),\n",
    "   'y': y\n",
    "  }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'n' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mNameError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-dc966d68458f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mdat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMakeHist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistogram\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbins\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'toks'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdat\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'barmode'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m'overlay'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'n' is not defined"
     ]
    }
   ],
   "source": [
    "dat = MakeHist(np.histogram(n, bins=30), name='toks')\n",
    "\n",
    "fig = fig = go.Figure(data=[dat], layout={'barmode':'overlay'})\n",
    "plotly.offline.plot(fig, filename='/home/tucker/Downloads/imdb_size_distci.html')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "attn = torch.nn.Sigmoid()(model.char_embedder.char_block_attn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sb = model.char_embedder.switchboard[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/tucker/Downloads/strategy_heatmap.html'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hm = go.Heatmap(z=sb.detach().cpu().numpy())\n",
    "fig = go.Figure(data=[hm])\n",
    "plotly.offline.plot(fig, filename='/home/tucker/Downloads/strategy_heatmap.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 384])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attn.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "attn_acts = attn.reshape(-1).detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/tucker/Downloads/act_dist.html'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat = MakeHist(np.histogram(attn_acts, bins=30), name='toks')\n",
    "fig = fig = go.Figure(data=[dat], layout={'barmode':'overlay'})\n",
    "plotly.offline.plot(fig, filename='/home/tucker/Downloads/act_dist.html')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([96, 384])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "chrs = []\n",
    "for enc in inputs[-1:]:\n",
    "  chrs.append(GetChars(enc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"the writer's intent. there's a lot of historical, literary, and biblical allusions which add to the complexity of the movie, and ultimately i think it adds depth and helps us to understand the transformations of the characters. the movie is all the more amazing when you consider it is based on a true story. i would recommend this_____________________________________________________\""
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chrs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/tucker/Downloads/strategy_heatmap.html'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hm = go.Heatmap(z=attn.detach().cpu().numpy())\n",
    "fig = go.Figure(data=[hm])\n",
    "plotly.offline.plot(fig, filename='/home/tucker/Downloads/strategy_heatmap.html')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "count = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/tucker/Downloads/strategy_heatmap.html'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import plotly.figure_factory as ff\n",
    "hm = ff.create_annotated_heatmap(\n",
    "  z=attn[:count].detach().cpu().numpy(), annotation_text=chrs[:count],\n",
    "  text=attn[:count].detach().cpu().numpy(), hoverinfo='text')\n",
    "\n",
    "plotly.offline.plot(hm, filename='/home/tucker/Downloads/strategy_heatmap.html')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from experiment import IdentityConv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "idc = IdentityConv(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sequence = torch.tensor([[1,2,3,4,5,6,7]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "emb = torch.nn.Embedding(10, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "embedded = emb(sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 7, 4])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.2802,  0.1562, -1.0467, -0.2609],\n",
       "         [-1.4873, -0.2946,  0.3285,  0.0856],\n",
       "         [ 0.2202, -1.6364, -0.4096, -0.6284],\n",
       "         [ 0.3340, -0.0501,  2.0443,  0.1030],\n",
       "         [ 1.4272, -2.0116,  0.3527, -1.3549],\n",
       "         [ 0.7472, -1.8266, -0.9577, -1.8917],\n",
       "         [-0.2680, -0.1245, -1.2108,  0.2656]]], grad_fn=<EmbeddingBackward>)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "uf = idc(embedded.permute(0,2,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[ 0.2802, -1.4873,  0.2202,  0.3340,  1.4272],\n",
       "          [-1.4873,  0.2202,  0.3340,  1.4272,  0.7472],\n",
       "          [ 0.2202,  0.3340,  1.4272,  0.7472, -0.2680],\n",
       "          [ 0.1562, -0.2946, -1.6364, -0.0501, -2.0116],\n",
       "          [-0.2946, -1.6364, -0.0501, -2.0116, -1.8266],\n",
       "          [-1.6364, -0.0501, -2.0116, -1.8266, -0.1245],\n",
       "          [-1.0467,  0.3285, -0.4096,  2.0443,  0.3527],\n",
       "          [ 0.3285, -0.4096,  2.0443,  0.3527, -0.9577],\n",
       "          [-0.4096,  2.0443,  0.3527, -0.9577, -1.2108],\n",
       "          [-0.2609,  0.0856, -0.6284,  0.1030, -1.3549],\n",
       "          [ 0.0856, -0.6284,  0.1030, -1.3549, -1.8917],\n",
       "          [-0.6284,  0.1030, -1.3549, -1.8917,  0.2656]]],\n",
       "        grad_fn=<PermuteBackward>),\n",
       " torch.Size([1, 12, 5]))"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uf, uf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sb = torch.tensor([[[0,1,0,0,0]]]).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 5])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dense = sb@uf.permute(0,2,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 12])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dense.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "argv": [
    "/usr/bin/python3",
    "-m",
    "ipykernel_launcher",
    "-f",
    "{connection_file}"
   ],
   "display_name": "Python 3",
   "env": null,
   "interrupt_mode": "signal",
   "language": "python",
   "metadata": null,
   "name": "python3"
  },
  "name": "ErrorAnalysis.ipynb"
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
